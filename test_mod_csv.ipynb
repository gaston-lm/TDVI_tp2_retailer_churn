{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import sklearn\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score, make_scorer\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "seed = 798589991"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_data = pd.read_csv(\"data/competition_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosas para hacer:\n",
    "\n",
    "- Platform -> pasar a una categoria que sea simplemente Desktop o Mobile.\n",
    "- Chequear si algun uid / user_id se repite, si no, no nos esta dando data y los podemos eliminar.\n",
    "- Garantia -> pasar a binario tiene o no tiene.\n",
    "- Foto -> no nos sirve a no ser que de alguna manera determinemos si es buena o mala calidad (bastante complicado a priori), eliminar.\n",
    "- Separar date en año, mes, dia, hora.\n",
    "- Deal print -> no parece aportar nada, son todos distintos, eliminar.\n",
    "- Category id, domain id, full name. Con category y domain tenemos la misma data que full name, podriamos eliminar full name y ver como funciona, porque su OHE va a ser eterno.\n",
    "- etl version es siempre lo mismo, eliminar.\n",
    "- title, product id e item id nos dan la misma informacion, dejar una.\n",
    "- \"benefit ignore should be dropped\" -> eliminar benefit\n",
    "- \"decimals ignore should be dropped\" -> eliminar decimals\n",
    "- hay descuento? -> original_price - price != 0, crear columna \"in_discount\"\n",
    "- rn leftover from ETL, discard -> eliminar rn.\n",
    "- ver si desagregar tags puede aportar algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropeo las columnas.\n",
    "comp_data.drop('benefit', inplace=True, axis=1)\n",
    "comp_data.drop('user_id', inplace=True, axis=1)\n",
    "comp_data.drop('uid', inplace=True, axis=1)\n",
    "comp_data.drop('main_picture', inplace=True, axis=1)\n",
    "comp_data.drop('full_name', inplace=True, axis=1)\n",
    "comp_data.drop('deal_print_id', inplace=True, axis=1)\n",
    "comp_data.drop('etl_version', inplace=True, axis=1)\n",
    "comp_data.drop('product_id', inplace=True, axis=1)\n",
    "comp_data.drop('title', inplace=True, axis=1)\n",
    "comp_data.drop('site_id', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feder\\AppData\\Local\\Temp\\ipykernel_9644\\2136878619.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  comp_data['platform'][i] = check_plat[2]\n"
     ]
    }
   ],
   "source": [
    "# Divido platform en solo Desktop, Ios, Android\n",
    "for i in range(len(comp_data['platform'])):\n",
    "    check_plat = comp_data['platform'][i].split('/')\n",
    "    comp_data['platform'][i] = check_plat[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformo garantía en una columna binaria (True, False, NaN)\n",
    "warranty = [True] * 199972\n",
    "for i in range(len(comp_data['warranty'])):\n",
    "    if comp_data['warranty'][i] == \"Sin garantía\":\n",
    "        warranty[i] = False\n",
    "    else:\n",
    "        if pd.notna(comp_data['warranty'][i]):\n",
    "            warranty[i] = True\n",
    "        else:\n",
    "            warranty[i] = np.nan\n",
    "\n",
    "comp_data['binary_warranty'] = warranty\n",
    "comp_data.drop('warranty', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo una columna con el descuento (en porcentaje).\n",
    "\n",
    "discount = ((comp_data['original_price'] - comp_data['price']) / comp_data['original_price']) * 100\n",
    "comp_data['discount_%'] = discount\n",
    "\n",
    "comp_data.drop('original_price', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good_quality_picture',\n",
       " 'good_quality_thumbnail',\n",
       " 'today_promotion',\n",
       " 'brand_verified',\n",
       " 'extended_warranty_eligible',\n",
       " 'immediate_payment',\n",
       " 'cart_eligible',\n",
       " 'incomplete_technical_specs',\n",
       " 'loyalty_discount_eligible',\n",
       " 'deal_of_the_day',\n",
       " 'dragged_bids_and_visits',\n",
       " 'lightning_deal',\n",
       " 'poor_quality_picture',\n",
       " 'ahora-12',\n",
       " 'catalog_listing_eligible',\n",
       " 'poor_quality_thumbnail',\n",
       " 'supermarket_eligible',\n",
       " 'under_infractions']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Consigo los tags posibles.\n",
    "unique_tags = []\n",
    "for list in comp_data['tags']:\n",
    "    list_split = list[1:len(list)-1].split(', ')\n",
    "    for item in list_split:\n",
    "        if not (item in unique_tags):\n",
    "            unique_tags.append(item)\n",
    "\n",
    "unique_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separo los tags en columnas de booleanos.\n",
    "for tag in unique_tags:\n",
    "    comp_data[tag] = comp_data['tags'].apply(lambda x: tag in x)\n",
    "\n",
    "comp_data.drop('tags', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding\n",
    "\n",
    "columns_to_encode = ['category_id', 'item_id', 'listing_type_id', 'logistic_type', 'platform']\n",
    "\n",
    "# Apply one-hot encoding to categorical columns\n",
    "encoded_columns = pd.get_dummies(comp_data[columns_to_encode], drop_first=True)\n",
    "\n",
    "# Concatenate the original DataFrame and the one-hot encoded columns\n",
    "comp_data_encoded = pd.concat([comp_data, encoded_columns], axis=1)\n",
    "\n",
    "# Drop the original categorical columns\n",
    "comp_data_encoded.drop(columns=columns_to_encode, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_data['binary_warranty'] = comp_data['binary_warranty'].astype(bool)\n",
    "comp_data = pd.get_dummies(comp_data, columns=['platform'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['date', 'domain_id', 'is_pdp', 'item_id', 'listing_type_id', 'logistic_type', 'print_server_timestamp'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m object_columns \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdomain_id\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mis_pdp\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mitem_id\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlisting_type_id\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlogistic_type\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mprint_server_timestamp\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcategory_id\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m----> 2\u001b[0m comp_data\u001b[39m.\u001b[39;49mdrop(columns\u001b[39m=\u001b[39;49mobject_columns, inplace\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[1;32md:\\Programas\\Conda\\envs\\TD6\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32md:\\Programas\\Conda\\envs\\TD6\\Lib\\site-packages\\pandas\\core\\frame.py:5399\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5251\u001b[0m \u001b[39m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, allowed_args\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m   5252\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(  \u001b[39m# type: ignore[override]\u001b[39;00m\n\u001b[0;32m   5253\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5260\u001b[0m     errors: IgnoreRaise \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   5261\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   5262\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   5263\u001b[0m \u001b[39m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5264\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5397\u001b[0m \u001b[39m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5398\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5399\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mdrop(\n\u001b[0;32m   5400\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   5401\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m   5402\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[0;32m   5403\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   5404\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m   5405\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[0;32m   5406\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   5407\u001b[0m     )\n",
      "File \u001b[1;32md:\\Programas\\Conda\\envs\\TD6\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32md:\\Programas\\Conda\\envs\\TD6\\Lib\\site-packages\\pandas\\core\\generic.py:4505\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4503\u001b[0m \u001b[39mfor\u001b[39;00m axis, labels \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems():\n\u001b[0;32m   4504\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 4505\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_drop_axis(labels, axis, level\u001b[39m=\u001b[39;49mlevel, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   4507\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[0;32m   4508\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32md:\\Programas\\Conda\\envs\\TD6\\Lib\\site-packages\\pandas\\core\\generic.py:4546\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4544\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n\u001b[0;32m   4545\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 4546\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49mdrop(labels, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   4547\u001b[0m     indexer \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4549\u001b[0m \u001b[39m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4550\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Programas\\Conda\\envs\\TD6\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6934\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6932\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[0;32m   6933\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m-> 6934\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(labels[mask])\u001b[39m}\u001b[39;00m\u001b[39m not found in axis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6935\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[\u001b[39m~\u001b[39mmask]\n\u001b[0;32m   6936\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['date', 'domain_id', 'is_pdp', 'item_id', 'listing_type_id', 'logistic_type', 'print_server_timestamp'] not found in axis\""
     ]
    }
   ],
   "source": [
    "object_columns = ['category_id']\n",
    "comp_data.drop(columns=object_columns, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, The experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:category_id: object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m X_train, X_val, y_train, y_val \u001b[39m=\u001b[39m train_test_split(X, y, test_size \u001b[39m=\u001b[39m val_test_size, random_state \u001b[39m=\u001b[39m seed, stratify \u001b[39m=\u001b[39m y)\n\u001b[0;32m     16\u001b[0m \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39mXGBClassifier(objective \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbinary:logistic\u001b[39m\u001b[39m'\u001b[39m, seed \u001b[39m=\u001b[39m seed, eval_metric \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mauc\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X_train, y_train, eval_set \u001b[39m=\u001b[39;49m [(X_val, y_val)])\n\u001b[0;32m     19\u001b[0m \u001b[39m# Chequeamos el valor debajo de la curva AUC-ROC\u001b[39;00m\n\u001b[0;32m     20\u001b[0m y_pred \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mpredict_proba(X_val)[:, \u001b[39m1\u001b[39m]\n",
      "File \u001b[1;32md:\\Programas\\Conda\\envs\\TD6\\Lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32md:\\Programas\\Conda\\envs\\TD6\\Lib\\site-packages\\xgboost\\sklearn.py:1471\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1460\u001b[0m     params[\u001b[39m\"\u001b[39m\u001b[39mnum_class\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_\n\u001b[0;32m   1462\u001b[0m (\n\u001b[0;32m   1463\u001b[0m     model,\n\u001b[0;32m   1464\u001b[0m     metric,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1469\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[0;32m   1470\u001b[0m )\n\u001b[1;32m-> 1471\u001b[0m train_dmatrix, evals \u001b[39m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m   1472\u001b[0m     missing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmissing,\n\u001b[0;32m   1473\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m   1474\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m   1475\u001b[0m     group\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   1476\u001b[0m     qid\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   1477\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1478\u001b[0m     base_margin\u001b[39m=\u001b[39;49mbase_margin,\n\u001b[0;32m   1479\u001b[0m     feature_weights\u001b[39m=\u001b[39;49mfeature_weights,\n\u001b[0;32m   1480\u001b[0m     eval_set\u001b[39m=\u001b[39;49meval_set,\n\u001b[0;32m   1481\u001b[0m     sample_weight_eval_set\u001b[39m=\u001b[39;49msample_weight_eval_set,\n\u001b[0;32m   1482\u001b[0m     base_margin_eval_set\u001b[39m=\u001b[39;49mbase_margin_eval_set,\n\u001b[0;32m   1483\u001b[0m     eval_group\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   1484\u001b[0m     eval_qid\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   1485\u001b[0m     create_dmatrix\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_dmatrix,\n\u001b[0;32m   1486\u001b[0m     enable_categorical\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menable_categorical,\n\u001b[0;32m   1487\u001b[0m     feature_types\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_types,\n\u001b[0;32m   1488\u001b[0m )\n\u001b[0;32m   1490\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[0;32m   1491\u001b[0m     params,\n\u001b[0;32m   1492\u001b[0m     train_dmatrix,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1501\u001b[0m     callbacks\u001b[39m=\u001b[39mcallbacks,\n\u001b[0;32m   1502\u001b[0m )\n\u001b[0;32m   1504\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n",
      "File \u001b[1;32md:\\Programas\\Conda\\envs\\TD6\\Lib\\site-packages\\xgboost\\sklearn.py:448\u001b[0m, in \u001b[0;36m_wrap_evaluation_matrices\u001b[1;34m(missing, X, y, group, qid, sample_weight, base_margin, feature_weights, eval_set, sample_weight_eval_set, base_margin_eval_set, eval_group, eval_qid, create_dmatrix, enable_categorical, feature_types)\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_wrap_evaluation_matrices\u001b[39m(\n\u001b[0;32m    429\u001b[0m     missing: \u001b[39mfloat\u001b[39m,\n\u001b[0;32m    430\u001b[0m     X: Any,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    444\u001b[0m     feature_types: Optional[FeatureTypes],\n\u001b[0;32m    445\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Any, List[Tuple[Any, \u001b[39mstr\u001b[39m]]]:\n\u001b[0;32m    446\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Convert array_like evaluation matrices into DMatrix.  Perform validation on the\u001b[39;00m\n\u001b[0;32m    447\u001b[0m \u001b[39m    way.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 448\u001b[0m     train_dmatrix \u001b[39m=\u001b[39m create_dmatrix(\n\u001b[0;32m    449\u001b[0m         data\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    450\u001b[0m         label\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    451\u001b[0m         group\u001b[39m=\u001b[39;49mgroup,\n\u001b[0;32m    452\u001b[0m         qid\u001b[39m=\u001b[39;49mqid,\n\u001b[0;32m    453\u001b[0m         weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    454\u001b[0m         base_margin\u001b[39m=\u001b[39;49mbase_margin,\n\u001b[0;32m    455\u001b[0m         feature_weights\u001b[39m=\u001b[39;49mfeature_weights,\n\u001b[0;32m    456\u001b[0m         missing\u001b[39m=\u001b[39;49mmissing,\n\u001b[0;32m    457\u001b[0m         enable_categorical\u001b[39m=\u001b[39;49menable_categorical,\n\u001b[0;32m    458\u001b[0m         feature_types\u001b[39m=\u001b[39;49mfeature_types,\n\u001b[0;32m    459\u001b[0m         ref\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    460\u001b[0m     )\n\u001b[0;32m    462\u001b[0m     n_validation \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m eval_set \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mlen\u001b[39m(eval_set)\n\u001b[0;32m    464\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mvalidate_or_none\u001b[39m(meta: Optional[Sequence], name: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Sequence:\n",
      "File \u001b[1;32md:\\Programas\\Conda\\envs\\TD6\\Lib\\site-packages\\xgboost\\sklearn.py:908\u001b[0m, in \u001b[0;36mXGBModel._create_dmatrix\u001b[1;34m(self, ref, **kwargs)\u001b[0m\n\u001b[0;32m    906\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:  \u001b[39m# `QuantileDMatrix` supports lesser types than DMatrix\u001b[39;00m\n\u001b[0;32m    907\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[1;32m--> 908\u001b[0m \u001b[39mreturn\u001b[39;00m DMatrix(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs, nthread\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs)\n",
      "File \u001b[1;32md:\\Programas\\Conda\\envs\\TD6\\Lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32md:\\Programas\\Conda\\envs\\TD6\\Lib\\site-packages\\xgboost\\core.py:743\u001b[0m, in \u001b[0;36mDMatrix.__init__\u001b[1;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical)\u001b[0m\n\u001b[0;32m    740\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    741\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 743\u001b[0m handle, feature_names, feature_types \u001b[39m=\u001b[39m dispatch_data_backend(\n\u001b[0;32m    744\u001b[0m     data,\n\u001b[0;32m    745\u001b[0m     missing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmissing,\n\u001b[0;32m    746\u001b[0m     threads\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnthread,\n\u001b[0;32m    747\u001b[0m     feature_names\u001b[39m=\u001b[39;49mfeature_names,\n\u001b[0;32m    748\u001b[0m     feature_types\u001b[39m=\u001b[39;49mfeature_types,\n\u001b[0;32m    749\u001b[0m     enable_categorical\u001b[39m=\u001b[39;49menable_categorical,\n\u001b[0;32m    750\u001b[0m )\n\u001b[0;32m    751\u001b[0m \u001b[39massert\u001b[39;00m handle \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    752\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle \u001b[39m=\u001b[39m handle\n",
      "File \u001b[1;32md:\\Programas\\Conda\\envs\\TD6\\Lib\\site-packages\\xgboost\\data.py:957\u001b[0m, in \u001b[0;36mdispatch_data_backend\u001b[1;34m(data, missing, threads, feature_names, feature_types, enable_categorical)\u001b[0m\n\u001b[0;32m    955\u001b[0m     \u001b[39mreturn\u001b[39;00m _from_tuple(data, missing, threads, feature_names, feature_types)\n\u001b[0;32m    956\u001b[0m \u001b[39mif\u001b[39;00m _is_pandas_df(data):\n\u001b[1;32m--> 957\u001b[0m     \u001b[39mreturn\u001b[39;00m _from_pandas_df(data, enable_categorical, missing, threads,\n\u001b[0;32m    958\u001b[0m                            feature_names, feature_types)\n\u001b[0;32m    959\u001b[0m \u001b[39mif\u001b[39;00m _is_pandas_series(data):\n\u001b[0;32m    960\u001b[0m     \u001b[39mreturn\u001b[39;00m _from_pandas_series(\n\u001b[0;32m    961\u001b[0m         data, missing, threads, enable_categorical, feature_names, feature_types\n\u001b[0;32m    962\u001b[0m     )\n",
      "File \u001b[1;32md:\\Programas\\Conda\\envs\\TD6\\Lib\\site-packages\\xgboost\\data.py:404\u001b[0m, in \u001b[0;36m_from_pandas_df\u001b[1;34m(data, enable_categorical, missing, nthread, feature_names, feature_types)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_from_pandas_df\u001b[39m(\n\u001b[0;32m    397\u001b[0m     data: DataFrame,\n\u001b[0;32m    398\u001b[0m     enable_categorical: \u001b[39mbool\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    402\u001b[0m     feature_types: Optional[FeatureTypes],\n\u001b[0;32m    403\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DispatchedDataBackendReturnType:\n\u001b[1;32m--> 404\u001b[0m     data, feature_names, feature_types \u001b[39m=\u001b[39m _transform_pandas_df(\n\u001b[0;32m    405\u001b[0m         data, enable_categorical, feature_names, feature_types\n\u001b[0;32m    406\u001b[0m     )\n\u001b[0;32m    407\u001b[0m     \u001b[39mreturn\u001b[39;00m _from_numpy_array(data, missing, nthread, feature_names, feature_types)\n",
      "File \u001b[1;32md:\\Programas\\Conda\\envs\\TD6\\Lib\\site-packages\\xgboost\\data.py:378\u001b[0m, in \u001b[0;36m_transform_pandas_df\u001b[1;34m(data, enable_categorical, feature_names, feature_types, meta, meta_type)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtypes\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m    367\u001b[0m     is_sparse,\n\u001b[0;32m    368\u001b[0m     is_categorical_dtype,\n\u001b[0;32m    369\u001b[0m )\n\u001b[0;32m    371\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m(\n\u001b[0;32m    372\u001b[0m     dtype\u001b[39m.\u001b[39mname \u001b[39min\u001b[39;00m _pandas_dtype_mapper\n\u001b[0;32m    373\u001b[0m     \u001b[39mor\u001b[39;00m is_sparse(dtype)\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m     \u001b[39mfor\u001b[39;00m dtype \u001b[39min\u001b[39;00m data\u001b[39m.\u001b[39mdtypes\n\u001b[0;32m    377\u001b[0m ):\n\u001b[1;32m--> 378\u001b[0m     _invalid_dataframe_dtype(data)\n\u001b[0;32m    380\u001b[0m feature_names, feature_types \u001b[39m=\u001b[39m _pandas_feature_info(\n\u001b[0;32m    381\u001b[0m     data, meta, feature_names, feature_types, enable_categorical\n\u001b[0;32m    382\u001b[0m )\n\u001b[0;32m    384\u001b[0m transformed \u001b[39m=\u001b[39m _pandas_cat_null(data)\n",
      "File \u001b[1;32md:\\Programas\\Conda\\envs\\TD6\\Lib\\site-packages\\xgboost\\data.py:270\u001b[0m, in \u001b[0;36m_invalid_dataframe_dtype\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    268\u001b[0m type_err \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mDataFrame.dtypes for data must be int, float, bool or category.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    269\u001b[0m msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\"\"\u001b[39m\u001b[39m{\u001b[39;00mtype_err\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m_ENABLE_CAT_ERR\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00merr\u001b[39m}\u001b[39;00m\u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m--> 270\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, The experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:category_id: object"
     ]
    }
   ],
   "source": [
    "# Dividimos entre la data que tenemos y la de evaluación para submitear.\n",
    "\n",
    "# La información que tenemos para entrenar y validar.\n",
    "local_data = comp_data[comp_data[\"ROW_ID\"].isna()]\n",
    "\n",
    "# La información en la que no tenemos las y, para predecir con el modelo ya entrenado y subir a Kaggle.\n",
    "kaggle_data = comp_data[comp_data[\"ROW_ID\"].notna()] \n",
    "\n",
    "# Entrenamos un modelo de xgboost\n",
    "y = local_data[['conversion']].copy()\n",
    "X = local_data.drop(columns=['conversion', 'ROW_ID'], axis = 1)\n",
    "\n",
    "val_test_size = 0.3 # Proporción de la suma del test de validación y del de test.\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = val_test_size, random_state = seed, stratify = y)\n",
    "\n",
    "cls = xgb.XGBClassifier(objective = 'binary:logistic', seed = seed, eval_metric = 'auc')\n",
    "cls.fit(X_train, y_train, eval_set = [(X_val, y_val)])\n",
    "\n",
    "# Chequeamos el valor debajo de la curva AUC-ROC\n",
    "y_pred = cls.predict_proba(X_val)[:, 1]\n",
    "auc_roc = sklearn.metrics.roc_auc_score(y_val, y_pred)\n",
    "print('AUC-ROC validación: %0.5f' % auc_roc)\n",
    "\n",
    "\n",
    "# Predicción en la data de kaggle para submitear.\n",
    "kaggle_data = kaggle_data.drop(columns=[\"conversion\"])\n",
    "y_preds = cls.predict_proba(kaggle_data.drop(columns=[\"ROW_ID\"]))[:, cls.classes_ == 1].squeeze()\n",
    "\n",
    "# Generamos el archivo para submit en base a lo predicho.\n",
    "submission_df = pd.DataFrame({\"ROW_ID\": kaggle_data[\"ROW_ID\"], \"conversion\": y_preds})\n",
    "submission_df[\"ROW_ID\"] = submission_df[\"ROW_ID\"].astype(int)\n",
    "submission_df.to_csv(\"xgboost_model/xgboost_model.csv\", sep=\",\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "td6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
